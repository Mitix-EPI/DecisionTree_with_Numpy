{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, depth=30, max_samples_leaves=50): # absurb values bcs not subject of the assignment ;)\n",
    "        self.depth = depth\n",
    "        self.max_samples_leaves = max_samples_leaves\n",
    "\n",
    "        self.count_depth = 0\n",
    "        self.count_max_samples_leaves = 0\n",
    "\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.nb_features = X.shape[1]\n",
    "        self.count_depth = 0\n",
    "        self.count_max_samples_leaves = 0\n",
    "\n",
    "        # Start the recursive alg\n",
    "        self.tree = self._algorithm(X, y)\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # Multiclass gini index\n",
    "    def _gini_index(self, y):\n",
    "        total = len(y)\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        # {0: 7, 1: 4, 2: 1, 3: 2, 4: 1}\n",
    "\n",
    "        gini_index = 1\n",
    "        for i in counter:\n",
    "            prob = counter[i] / total\n",
    "            gini_index -= (prob ** 2)\n",
    "        return gini_index\n",
    "\n",
    "    def _calc_weighted_average_impurity(self, left, right):\n",
    "        gini_indexe_left = self._gini_index(left[:, -1]) if len(left) > 0 else 0\n",
    "        gini_indexe_right = self._gini_index(right[:, -1]) if len(right) > 0 else 0\n",
    "\n",
    "        total = len(left) + len(right)\n",
    "        average = ((len(left) / total) * gini_indexe_left) + ((len(right) / total) * gini_indexe_right)\n",
    "        return average\n",
    "\n",
    "    def _get_most_frequency_class(self, data):\n",
    "        values, counts = np.unique(data, return_counts=True)\n",
    "        return values[counts.argmax()]\n",
    "\n",
    "    # The assignment 2 said that when need to choose the mean\n",
    "    def _get_threshold(self, feature_index, data):\n",
    "        if (isinstance(data[:, feature_index][0], str)):\n",
    "            return self._get_most_frequency_class(data[:, feature_index])\n",
    "        else:\n",
    "            # Calculate the mean only for the feature indicated\n",
    "            return np.mean(data[:, feature_index])\n",
    "\n",
    "    # Index is the feature index\n",
    "    def _test_split(self, index, value, dataset):\n",
    "        left, right = [], []\n",
    "\n",
    "        for row in dataset:\n",
    "\n",
    "            if isinstance(value, str):\n",
    "                if row[index] == value:\n",
    "                    left.append(row)\n",
    "                else:\n",
    "                    right.append(row)\n",
    "            else:\n",
    "                if row[index] < value:\n",
    "                    left.append(row)\n",
    "                else:\n",
    "                    right.append(row)\n",
    "\n",
    "        return [np.array(left), np.array(right)]\n",
    "\n",
    "    # Get the index of the best feature\n",
    "    def _get_best_feature_to_split_on(self, dataset):\n",
    "\n",
    "        min_average_impurity = 999\n",
    "        feature_index = 0\n",
    "\n",
    "        # Trying all features\n",
    "        for i in range(self.nb_features):\n",
    "            threshold = self._get_threshold(i, dataset)\n",
    "            split_arr = self._test_split(i, threshold, dataset)\n",
    "            average_impurity = self._calc_weighted_average_impurity(split_arr[0], split_arr[1])\n",
    "\n",
    "            if average_impurity < min_average_impurity:\n",
    "                min_average_impurity = average_impurity\n",
    "                feature_index = i\n",
    "\n",
    "        return feature_index\n",
    "\n",
    "    # The Decision Tree multi-class classifier algorithm\n",
    "    def _algorithm(self, X, y):\n",
    "        dataset = np.column_stack([X, y])\n",
    "\n",
    "        if (self._homogenuous(dataset) or self.count_depth == self.depth or self.count_max_samples_leaves == self.max_samples_leaves):\n",
    "            self.count_max_samples_leaves += 1\n",
    "            # Stop the recursive\n",
    "            return {\"label\": self._labelize(dataset), \"threshold\": None, \"left\": None, \"right\": None}\n",
    "\n",
    "        index_feature = self._get_best_feature_to_split_on(dataset)\n",
    "        threshold = self._get_threshold(index_feature, dataset)\n",
    "        split_arr = self._test_split(index_feature, threshold, dataset)\n",
    "        \n",
    "        try:\n",
    "            left, right = split_arr\n",
    "            left_X, left_y = left[:, :-1], left[:, -1]\n",
    "            right_X, right_y = right[:, :-1], right[:, -1]\n",
    "            self.count_depth += 1\n",
    "        except:\n",
    "            print(left, right)\n",
    "\n",
    "        left_tree = self._algorithm(left_X, left_y)\n",
    "        right_tree = self._algorithm(right_X, right_y)\n",
    "\n",
    "        return {\"index\": index_feature, \"threshold\": threshold, \"left\": left_tree, \"right\": right_tree}\n",
    "\n",
    "    def _homogenuous(self, dataset):\n",
    "        y = dataset[:, -1]\n",
    "        total = len(y)\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        # {0: 7, 1: 4, 2: 1, 3: 2, 4: 1}\n",
    "\n",
    "        max_prob = 0\n",
    "        for i in counter:\n",
    "            prob = counter[i] / total\n",
    "\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "\n",
    "        # If one class has 90% frequency, return this class\n",
    "        if max_prob > 0.90:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Return the value of the most frequent label\n",
    "    def _labelize(self, dataset):\n",
    "        y = dataset[:, -1]\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        ind = np.argmax(counts)\n",
    "        return values[ind]\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for row in X:\n",
    "            predictions.append(self._predict_one(row, self.tree))\n",
    "        return predictions\n",
    "    \n",
    "    # Go through linked node\n",
    "    def _predict_one(self, row, tree):\n",
    "        if tree[\"left\"] is None and tree[\"right\"] is None:\n",
    "            return tree[\"label\"]\n",
    "        \n",
    "        if row[tree[\"index\"]] < tree[\"threshold\"]:\n",
    "            return self._predict_one(row, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_one(row, tree[\"right\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Train and Test model through different datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 2 useful functions from assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tmls_to_X_and_y(data, label_to_remove = None):\n",
    "    new_data = data.sample(frac = 1) # Suffle rows of the data set\n",
    "    if (not(label_to_remove is None)):\n",
    "        new_data = new_data[new_data[\"class\"] != label_to_remove] # Drop class\n",
    "    X = new_data.iloc[:, 0:-1]#.apply(pd.to_numeric, errors='coerce')\n",
    "    X = (\n",
    "        X.apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "            .fillna(X)\n",
    "    )\n",
    "    y = new_data.iloc[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of the model\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    # Number of correct predictions\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "\n",
    "    total = len(y_true)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode the `train_test_split` function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X, y, test_size=0.33):\n",
    "    # This function supposes that we already have randomized rows\n",
    "    size = X.shape[0]\n",
    "    index = int(size - (size * test_size))\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    return X[:index], X[index:], y[:index], y[index:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can setup a generic environment for tmls datasets\n",
    "\n",
    "*Note: cancer.csv has been formated manually into cancer.tmls*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset\n",
      "Run 1 - Accuracy  0.94\n",
      "Run 2 - Accuracy  1.0\n",
      "Run 3 - Accuracy  0.96\n",
      "Run 4 - Accuracy  0.98\n",
      "Run 5 - Accuracy  0.92\n",
      "\n",
      "\n",
      "wine dataset\n",
      "Run 1 - Accuracy  0.9152542372881356\n",
      "Run 2 - Accuracy  0.8983050847457628\n",
      "Run 3 - Accuracy  0.8813559322033898\n",
      "Run 4 - Accuracy  0.9152542372881356\n",
      "Run 5 - Accuracy  0.8813559322033898\n",
      "\n",
      "\n",
      "cancer dataset\n",
      "Run 1 - Accuracy  0.9361702127659575\n",
      "Run 2 - Accuracy  0.9308510638297872\n",
      "Run 3 - Accuracy  0.9095744680851063\n",
      "Run 4 - Accuracy  0.9095744680851063\n",
      "Run 5 - Accuracy  0.9308510638297872\n",
      "\n",
      "\n",
      "adult dataset\n",
      "Run 1 - Accuracy  0.7402283161682591\n",
      "Run 2 - Accuracy  0.7371261943169127\n",
      "Run 3 - Accuracy  0.7406005707904206\n",
      "Run 4 - Accuracy  0.7335897754063779\n",
      "Run 5 - Accuracy  0.737808661124209\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234) # Set initial random seed (good to always do)\n",
    "\n",
    "\n",
    "for dataset_name in [\"iris\", \"wine\", \"cancer\", \"adult\"]:\n",
    "    file_path = dataset_name + \".tmls\"\n",
    "\n",
    "    print(dataset_name + \" dataset\")\n",
    "\n",
    "    for i in range(5):\n",
    "        # Open dataset\n",
    "        df_dataset = pd.read_csv(file_path)\n",
    "        df_dataset = df_dataset.dropna() # Remove NaN\n",
    "        data = df_dataset.drop(0) # Remove first row\n",
    "        X, y = split_tmls_to_X_and_y(data)\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = my_train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "        dt = DecisionTreeClassifier()\n",
    "        dt.fit(X_train, y_train)\n",
    "        pred = dt.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        print(\"Run \" + str(i + 1) + \" - Accuracy \", accuracy)\n",
    "\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
